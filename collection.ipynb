{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeneWim/ACTHProject/blob/Moritz/collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from pandas) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: rdflib in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (7.1.4)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from rdflib) (3.2.3)\n",
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from SPARQLWrapper) (7.1.4)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\mobai\\acthproject\\.venv\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.2.3)\n",
            "Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# Setup: install panda\n",
        "!pip install pandas \n",
        "# Setup: install rdflib\n",
        "!pip install rdflib\n",
        "#Setup: install SPARQLWrapper\n",
        "!pip install SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R7y7tVAGJE7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "import requests\n",
        "from rdflib.namespace import RDF\n",
        "from rdflib import Namespace\n",
        "import pickle\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CRM = Namespace(\"http://www.cidoc-crm.org/cidoc-crm/\") #creating a namespace object\n",
        "g.bind(\"crm\", CRM) # binding it to the graph so when we serialize it, it will use\n",
        "#crm:something instead of the full namespace\n",
        "DC = Namespace(\"http://purl.org/dc/elements/1.1/\")\n",
        "g.bind(\"dc\", DC)\n",
        "FOAF = Namespace(\"<http://xmlns.com/foaf/0.1/\") \n",
        "g.bind(\"foaf\", FOAF)\n",
        "NS1 = Namespace(\"http://schema.org/\")\n",
        "g.bind(\"ns1\", NS1)\n",
        "XSD = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
        "g.bind(\"xsd\", XSD)\n",
        "W3 = Namespace(\"https://w3id.org/i40/sto\")\n",
        "g.bind(\"w3\", W3)\n",
        "EX = Namespace(\"http://w3id.org/example/\")\n",
        "g.bind(\"ex\", EX)\n",
        "\n",
        "\n",
        "\n",
        "from Artifact import Artifact\n",
        "from Artist import Artist\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Collection:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "        self.artists = []  # List of Artist objects\n",
        "        self.artifacts = []  # List of Artifact objects\n",
        "\n",
        "    def add_artifact(self, artifact: Artifact):\n",
        "        if not isinstance(artifact, Artifact):\n",
        "            raise TypeError(\"Expected an instance of Artifact\")\n",
        "\n",
        "        self.artifacts.append(artifact)\n",
        "\n",
        "    def add_artist(self, artist: Artist):\n",
        "        if not isinstance(artist, Artist):\n",
        "            raise TypeError(\"Expected an instance of Artist\")\n",
        "\n",
        "        self.artists.append(artist)\n",
        "\n",
        "    def to_rdf(self):\n",
        "        # returns an rdflib.Graph with all RDF triples from the collection â€“\n",
        "        # artifacts and their creators must be linked!\n",
        "        # **Not every single attribute needs to be represented in RDF, keep it simple as a proof of concept**\n",
        "        '''\n",
        "        from rdflib import Graph, Namespace, Literal, RDF, URIRef, FOAF\n",
        "\n",
        "        g = Graph()\n",
        "\n",
        "        # Add a few triples\n",
        "        g.add((ex.artifact, RDF.type, ex.artist))\n",
        "\n",
        "        # Query the graph\n",
        "        query = \"\"\"\n",
        "        prefix ex: \n",
        "        prefix foaf: \n",
        "        SELECT ?name ?place WHERE {\n",
        "        ?painter a ex:artist ;\n",
        "                foaf:name ?name  .\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        results = g.query(query)\n",
        "\n",
        "        for row in results:\n",
        "            print(f\"{row.name} was born in {row.place}\")\n",
        "        '''\n",
        "                \n",
        "          \n",
        "       \n",
        "        \n",
        "    def visualize_metadata(self):\n",
        "        # generates visualizations from the raw dataset (e.g. pie charts, bar charts) up to you which ones\n",
        "\n",
        "        '''\n",
        "        df = pd.read_csv(\"../Data/MetObjects_Cleaned.csv\", low_memory=False)\n",
        "\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def visualize_rdf(self):\n",
        "        # generates RDF visualizations\n",
        "\n",
        "        '''\n",
        "        for i, name in enumerate(artifacts):\n",
        "            art = EX[f\"artifact{i}\"]\n",
        "            prod = EX[f\"production{i}\"]\n",
        "            g.add((art, RDF.type, CRM[\"E22_Man-Made_Object\"]))\n",
        "            g.add((art, RDFS.label, Literal(name)))\n",
        "            g.add((art, CRM[\"P108i_was_produced_by\"], prod))\n",
        "            g.add((prod, CRM[\"P7_took_place_at\"], Literal(random.choice(sites))))\n",
        "            g.add((prod, CRM[\"P4_has_time-span\"], Literal(random.choice(periods))))\n",
        "            g.add((art, CRM[\"P45_consists_of\"], Literal(random.choice(materials))))\n",
        "\n",
        "                pass\n",
        "            \n",
        "        \n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "    def cross_api_enrich(self):\n",
        "        # finds additional works by the artists in the collection from the AIC or Cleveland API,\n",
        "        # adds the items to the collection (with the metadata that they have from the APIs,\n",
        "        # so you should consider about their metadata as well when you create attributes.\n",
        "        # Remember you can put default attributes as None for things that are not shared between the APIs\n",
        "\n",
        "        '''\n",
        "        endpoint_url = \"https://query.wikidata.org/sparql\"\n",
        "        sparql = SPARQLWrapper(endpoint_url)\n",
        "        sparql.setReturnFormat(JSON)\n",
        "\n",
        "        #if loop class has URL won Wikidata -> suche\n",
        "\n",
        "        query = \"\"\"\n",
        "        SELECT ?person ?personLabel ?birthplaceLabel WHERE {\n",
        "        ?person wdt:P106 wd:Q1028181;   # occupation: painter\n",
        "                wdt:P800 ?work;         # notable work\n",
        "                wdt:P19 ?birthplace.    # place of birth\n",
        "        ?work wdt:P135 wd:Q4692.        # renaissance movement\n",
        "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
        "        }\n",
        "        LIMIT 5\n",
        "\n",
        "         sparql.setQuery(query)\n",
        "        results = sparql.query().convert()\n",
        "    '''\n",
        "    '''\n",
        "    def get_artist_bio(description_word, cached={}):\n",
        "                url = \"https://api.artic.edu/api/v1/artworks/search\"\n",
        "                headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "                payload = {\n",
        "                    \"query\": {\n",
        "                        \"bool\": {\n",
        "                            \"must\": [\n",
        "                                {\"match\": {\"description\": description_word}}\n",
        "                            ],\n",
        "                            \"filter\": [\n",
        "                                {\"term\": {\"is_public_domain\": True}}\n",
        "                            ]\n",
        "                        }\n",
        "                    }, \"fields\" : [\"artist_id\"] # we only care about the artist id for the second query\n",
        "                }\n",
        "\n",
        "                response = requests.post(url, headers=headers, json=payload)\n",
        "                result = response.json()\n",
        "                if result[\"data\"]:\n",
        "                    for res in result[\"data\"]:\n",
        "                        id = res[\"artist_id\"]\n",
        "                        if id not in cached:\n",
        "                            artist_url = \"https://api.artic.edu/api/v1/artists/\" + str(id) # we create the url\n",
        "                            response_art = requests.get(\"https://api.artic.edu/api/v1/artists/\" + str(id))\n",
        "                            data_art = response_art.json()\n",
        "                            cached[id] = {\"title\":data_art[\"data\"][\"title\"], \"birth_date\":data_art[\"data\"][\"birth_date\"], \"death_date\":data_art[\"data\"][\"death_date\"], \"description\":data_art[\"data\"][\"description\"]}\n",
        "                        else:\n",
        "                            print(f\"Using cached version of artist {id}: {cached[id]['title']}\")\n",
        "                return cached      \n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "       \n",
        "\n",
        "        '''\n",
        "\n",
        "        pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMOX2vpVi6DP/ReJ9Z595iR",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
